{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad9fa0e-4282-4137-aacf-fc58582729c7",
   "metadata": {},
   "source": [
    "# <b>0. IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b800da4-dd0b-48fa-8d3a-5308d4b9377f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml.dom.minidom\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90563490-b8d6-46c8-9012-09630cdcaa15",
   "metadata": {},
   "source": [
    "# <b> 1. Paths to directories and files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89571021-5127-4327-a036-a5c0be2161d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1 Donwloading the MNIST dataset from TF and preparing the directories to save the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166014ea-6873-4ec1-854e-7dd7c0906cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#donwload dataset mnist\n",
    "(x_train_ori, y_train_ori), (x_test_ori, y_test_ori) = tf.keras.datasets.mnist.load_data()\n",
    "assert x_train_ori.shape == (60000, 28, 28)\n",
    "assert x_test_ori.shape == (10000, 28, 28)\n",
    "assert y_train_ori.shape == (60000,)\n",
    "assert y_test_ori.shape == (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9384ac8-bdea-47fb-ac20-1c658b90a1c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#files path in a dictionary\n",
    "paths = dict()\n",
    "# Linux pc\n",
    "paths['main'] = '/home/javi/Desktop/Python/MNIST_OD'\n",
    "paths['dataset'] = os.path.join(paths['main'], 'MNIST_dataset')\n",
    "paths['train_data'] = os.path.join(paths['dataset'], 'train')\n",
    "paths['test_data'] = os.path.join(paths['dataset'], 'test')\n",
    "# Windows pc\n",
    "# paths['main'] = os.path.normcase('D:\\Javi\\Python\\MNIST_OD')#.replace('\\\\','/'))\n",
    "# paths['dataset'] = os.path.join(paths['main'], 'MNIST_dataset')\n",
    "# paths['train_data'] = os.path.join(paths['dataset'], 'train')\n",
    "# paths['test_data'] = os.path.join(paths['dataset'], 'test')\n",
    "# paths['test_img'] = os.path.join(paths['test_data'], 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f761f61e-0ad2-4981-afea-8bbc7007b6cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\javi\\python\\mnist_od\\MNIST_dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(paths['dataset'])\n",
    "os.path.exists(paths['train_data'])\n",
    "# print(paths['train_data'])/home/javi/Desktop/Python/MNIST_OD/Mnist_dataset/train\n",
    "# if 'Linux' in str(os.system('uname')):\n",
    "#     print('Es linux')\n",
    "# os.path.exists(paths['train_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2380a8-00ed-4b45-bdfa-f4eb2f3a2f6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2 Preparing the dataset to generate new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc6c9f6c-b7c1-4b63-9df1-2879b8fce326",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 01:36:42.785091: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#convert the raw data to a dataset-object\n",
    "\n",
    "train = tf.data.Dataset.from_tensor_slices((x_train_ori,y_train_ori))\n",
    "test = tf.data.Dataset.from_tensor_slices((x_test_ori,y_test_ori))\n",
    "\n",
    "#genetating the input data format\n",
    "BATCH = 5\n",
    "FETCH = 6\n",
    "SHUFFLE = 600\n",
    "\n",
    "\n",
    "train = train.batch(BATCH).shuffle(SHUFFLE).prefetch(FETCH)\n",
    "test = test.batch(BATCH).prefetch(FETCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43626707-d480-4fbb-ad71-7c56248b977e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Functions to preproccess images in to the new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f957a7f5-0dfd-40bf-8ccf-ea7cd4f1ef34",
   "metadata": {},
   "source": [
    "## 2.1 Functions to treat the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06eb081-b4c4-4918-8c00-54b3b7f04352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to rotate images\n",
    "\n",
    "def rotate_image(image, angle, not_print = True):\n",
    "    '''\n",
    "    This function rotate the image and plot it\n",
    "    Imput params:\n",
    "        image = array like,\n",
    "        angle = counterclockwise rotate angle (degrees),\n",
    "        not_print = if 'True' do not plot an image\n",
    "    Return:\n",
    "        image = image rotated [array like]\n",
    "    '''\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv.INTER_LINEAR)\n",
    "    if not not_print:\n",
    "        plt.imshow(result, cmap='gray')\n",
    "        plt.show()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497b7314-4dc0-4b54-846f-060968cd7f74",
   "metadata": {},
   "source": [
    "## 2.2 functions to create a pascal voc format sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edabe0a6-c2ef-4841-b0a2-3c7876e191d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a pascal voc format file from the dictionary data\n",
    "\n",
    "def dict_to_xml(tag, d, attribute=None):\n",
    "    '''\n",
    "    This function create a xml object from scratch\n",
    "    attributes:\n",
    "    - tag : str name of the top tag\n",
    "    - d : dict like to create child elemments in xml\n",
    "    - attribute : attribute for top tag (default=None)\n",
    "    return: xml object\n",
    "    '''\n",
    "    elem = ET.Element(tag)\n",
    "    if attribute is not None:\n",
    "        elem.attrib = attribute\n",
    "    for key, val in d.items():\n",
    "        child = ET.Element(key)\n",
    "        child.text = str(val)\n",
    "        elem.append(child)\n",
    "    return elem\n",
    "\n",
    "\n",
    "def add_dict_to_xml(xml, d):\n",
    "    '''\n",
    "    This function modify chilid elemments\n",
    "    for an xml object\n",
    "    attributes:\n",
    "    - xml : xml parent obj\n",
    "    - d : dict like to create child elemments in xml\n",
    "    return: None\n",
    "    '''\n",
    "    elem = xml\n",
    "    for key, val in d.items():\n",
    "        child = ET.Element(key)\n",
    "        child.text = str(val)\n",
    "        elem.append(child)\n",
    "\n",
    "\n",
    "def toPascalVocFormat(name_of_the_file, directory_name, dictionary_data):\n",
    "    '''\n",
    "    This function create a xml file.\n",
    "    Attributes:\n",
    "    - name_of_the_file: name of the file (str)\n",
    "    - directory_name: directory path to save the file (str)\n",
    "    - d: list of dict len(d)=number of objects in the image\n",
    "      d example: [{'name': 'Class_name', 'x_min': 'int',\n",
    "                   'ymin': 'int', 'xmax': 'int', 'ymax': 'int'}]\n",
    "    return: None\n",
    "    '''\n",
    "    # Baseline data in a dictionary format\n",
    "    basicXmlFileDict = {'folder': os.path.dirname(directory_name),\n",
    "                        'filename': name_of_the_file+'.jpg',\n",
    "                        'path': os.path.join(directory_name,\n",
    "                                             name_of_the_file+'.jpg')\n",
    "                       }\n",
    "\n",
    "    sizeDict = {'width': '144', 'height': '144', 'depth': '1'}\n",
    "\n",
    "    dummyObject = {'name': 'Class_name', 'pose': 'Unspecified',\n",
    "                   'truncated': '0', 'difficult': '0'}\n",
    "\n",
    "    dummyObjectBNB = {'xmin': 'int', 'ymin': 'int',\n",
    "                      'xmax': 'int', 'ymax': 'int'}\n",
    "\n",
    "    dummy_xml = dict_to_xml('annotation', basicXmlFileDict,\n",
    "                            attribute={'verified': 'no'})\n",
    "    dummy_xml.append(ET.Element('source'))\n",
    "    dummy_xml.find('source').append(ET.Element('database'))\n",
    "    dummy_xml.find('source')[0].text = 'MNIST dataset for OD by Javi'\n",
    "    dummy_xml.append(ET.Element('size'))\n",
    "    dummy_xml.append(ET.Element('segmented'))\n",
    "    dummy_xml.find('segmented').text = '0'\n",
    "    add_dict_to_xml(dummy_xml.find('size'), sizeDict)\n",
    "\n",
    "    for item in dictionary_data:\n",
    "        dummyObject['name'] = item['name']\n",
    "        dummyObjectBNB['xmin'] = item['xmin']\n",
    "        dummyObjectBNB['ymin'] = item['ymin']\n",
    "        dummyObjectBNB['xmax'] = item['xmax']\n",
    "        dummyObjectBNB['ymax'] = item['ymax']\n",
    "        child = ET.Element('object')\n",
    "        add_dict_to_xml(child, dummyObject)\n",
    "        dummy_xml.append(child)\n",
    "        ET.SubElement(dummy_xml[-1], 'bndbox')\n",
    "        add_dict_to_xml(dummy_xml[-1].find('bndbox'), dummyObjectBNB)\n",
    "    # Creating a xml in the directory\n",
    "    f = open(os.path.join(directory_name, name_of_the_file+'.xml'), \"w\")\n",
    "    file = ET.tostring(dummy_xml)\n",
    "    dom = xml.dom.minidom.parseString(file)\n",
    "    pretty_xml_as_string = dom.toprettyxml()\n",
    "    f.write(pretty_xml_as_string)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5c794a-c1f2-41d9-ac83-994780695681",
   "metadata": {},
   "source": [
    "## 2.3 Function to fine tune the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e84aa1-517a-49ef-a986-27af9607bb62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a function to increase the accuracy of the bounding box on the image\n",
    "\n",
    "def clossing_bnb(image, possition_list):\n",
    "    '''\n",
    "    This function take an image and the possition of an object in the image\n",
    "    and try to close the box arround the object til the first pixel not dark\n",
    "    Attributes:\n",
    "    - image: ndarry of the image\n",
    "    - possition_list: list of the initial possition of the object (list of lists)\n",
    "      example point inside possition list: [inital_row, initial_col, high(high=width)]\n",
    "    return: new possition of the objects [x_min, y_min, x_max, y_max]\n",
    "    '''\n",
    "    opt_bnb = list()\n",
    "    for p, point in enumerate(possition_list):\n",
    "        ROI = image[point[0]:point[0]+point[2], point[1]:point[1]+point[2]]\n",
    "        # Reducing the top\n",
    "        top = 0\n",
    "        stopper = True\n",
    "        threshold = 255\n",
    "        while stopper:\n",
    "            if ROI[-top-1, :].sum() < threshold:\n",
    "                top += 1\n",
    "            elif top >= point[2]:\n",
    "                print('The bnb become 0, something is wrong0')\n",
    "                break\n",
    "            else:\n",
    "                stopper = False\n",
    "        # Reducing the bottom\n",
    "        bot = 0\n",
    "        stopper = True\n",
    "        while stopper:\n",
    "            if ROI[bot+1, :].sum() < threshold:\n",
    "                bot += 1\n",
    "            elif bot >= point[2]:\n",
    "                print('The bnb become 0, something is wrong1')\n",
    "                break\n",
    "            else:\n",
    "                stopper = False\n",
    "        # Reducing the left\n",
    "        left = 0\n",
    "        stopper = True\n",
    "        while stopper:\n",
    "            if ROI[:, left+1].sum() < threshold:\n",
    "                left += 1\n",
    "            elif left >= point[2]:\n",
    "                print('The bnb become 0, something is wrong2')\n",
    "                break\n",
    "            else:\n",
    "                stopper = False\n",
    "        # Reducing the rigth\n",
    "        rigth = 0\n",
    "        stopper = True\n",
    "        while stopper:\n",
    "            if ROI[:, -rigth-1].sum() < threshold:\n",
    "                rigth += 1\n",
    "            elif rigth >= point[2]:\n",
    "                print('The bnb become 0, something is wrong3')\n",
    "                break\n",
    "            else:\n",
    "                stopper = False\n",
    "        opt_bnb.append([point[1]+left, point[0]+bot,\n",
    "                       point[1]+point[2]-rigth, point[0]+point[2]-top])\n",
    "\n",
    "    return opt_bnb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e054fb6-b27a-4f0c-854d-22ad427b2611",
   "metadata": {},
   "source": [
    "## 2.4 Main function to create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eaf196a-259b-40bb-90a9-5f7dcfc0d0b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to create a dataset image\n",
    "\n",
    "def image_generator(tf_dataset, number_of_images, directory_name):\n",
    "    # For every number_of_images that it is going to be created:\n",
    "    images, labels = tf_dataset.as_numpy_iterator().next()\n",
    "    batch_size = images.shape[0]\n",
    "    listOfPositions = list(range(batch_size))\n",
    "    for numb in tqdm(range(number_of_images)):\n",
    "        # take a banch of the dataset\n",
    "        images, labels = tf_dataset.as_numpy_iterator().next()\n",
    "        numberOfImages = random.randint(1, batch_size)\n",
    "        # take a random numberOfImages from the banch\n",
    "        indexOfImages = random.sample(listOfPositions, numberOfImages)\n",
    "        # generate a back image\n",
    "        img = np.zeros((144, 144), dtype=np.uint8)\n",
    "        positionList = list()\n",
    "        labelsList = list()\n",
    "        # For every image chose:\n",
    "        for noi in indexOfImages:\n",
    "            # Rotate the image and scaled 0.5 to 1.5 times\n",
    "            rotationAngle = random.randint(-45, 45)\n",
    "            scaleFactor = round((1.5*random.random()+0.5)*28)\n",
    "            # print(scaleFactor)\n",
    "            size = (scaleFactor, scaleFactor)\n",
    "            stopper = 0\n",
    "            # For every number noi, try to find a possition to do not overlap each other (5 tries):\n",
    "            while stopper <= 5:\n",
    "                # Generate random position\n",
    "                x = random.randint(0, 144-scaleFactor)\n",
    "                y = random.randint(0, 144-scaleFactor)\n",
    "                # print(x,y)\n",
    "                # Initilize the possition has available (not overlap)\n",
    "                positionCompromised = False\n",
    "                # Compare with the numbers already added to the black image\n",
    "                for pos in positionList:\n",
    "                    # print('Scales',pos[2],scaleFactor)\n",
    "                    # print(x, y, x+scaleFactor, y+scaleFactor)\n",
    "                    # print(pos[0],pos[1],pos[0]+pos[2],pos[1]+pos[2])\n",
    "                    # Is the new number size bigger than the old one\n",
    "                    if scaleFactor > pos[2]:\n",
    "                        # The points are True if old point inside square ->(x, y), (x+scale, y+scale)\n",
    "                        point1 = (pos[0] > x and pos[0] < x+scaleFactor) and (pos[1] > y and pos[1] < y+scaleFactor)\n",
    "                        point2 = (pos[0]+pos[2] > x and pos[0]+pos[2] < x+scaleFactor) and (pos[1] > y and pos[1] < y+scaleFactor)\n",
    "                        point3 = (pos[0]+pos[2] > x and pos[0]+pos[2] < x+scaleFactor) and (pos[1]+pos[2] > y and pos[1]+pos[2] < y+scaleFactor)\n",
    "                        point4 = (pos[0] > x and pos[0] < x+scaleFactor) and (pos[1]+pos[2] > y and pos[1]+pos[2] < y+scaleFactor)\n",
    "                    else:\n",
    "                        # The points are True if new point inside square -> pos\n",
    "                        point1 = (x > pos[0] and x < pos[0]+pos[2]) and (y > pos[1] and y < pos[1]+pos[2])\n",
    "                        point2 = (x+scaleFactor > pos[0] and x+scaleFactor < pos[0]+pos[2]) and (y > pos[1] and y < pos[1]+pos[2])\n",
    "                        point3 = (x+scaleFactor > pos[0] and x+scaleFactor < pos[0]+pos[2]) and (y+scaleFactor > pos[1] and y+scaleFactor < pos[1]+pos[2])\n",
    "                        point4 = (x > pos[0] and x < pos[0]+pos[2]) and (y+scaleFactor > pos[1] and y+scaleFactor < pos[1]+pos[2])\n",
    "                    # If any point is True the image is ocluding other one and is not included\n",
    "                    if point1 or point2 or point3 or point4:\n",
    "                        # print('denegado')\n",
    "                        positionCompromised = True\n",
    "                    # print(scaleFactor > pos[2],point1,point2,point3,point4)\n",
    "                if len(positionList) == 0:\n",
    "                    positionList.append([x, y, scaleFactor])\n",
    "                    labelsList.append(labels[noi])\n",
    "                    img[x:x+scaleFactor, y:y+scaleFactor] = rotate_image(cv.resize(images[noi], size), \n",
    "                                                                         rotationAngle, not_print = True)\n",
    "                    stopper = 10\n",
    "                elif not positionCompromised:\n",
    "                    # print('Premio')\n",
    "                    positionList.append([x, y, scaleFactor])\n",
    "                    labelsList.append(labels[noi])\n",
    "                    img[x:x+scaleFactor, y:y+scaleFactor] = rotate_image(cv.resize(images[noi], size), \n",
    "                                                                         rotationAngle, not_print = True)\n",
    "                    stopper = 10\n",
    "                stopper += 1\n",
    "        newPositionList = clossing_bnb(img, positionList)\n",
    "        # newPositionList = list()\n",
    "        # for box in positionList:\n",
    "        #     newPositionList.append([box[1], box[0], box[1]+box[2], box[0]+box[2]])\n",
    "        # print(newPositionList)\n",
    "        data_dic =  list()\n",
    "        for label, newPosition in zip(labelsList, newPositionList):\n",
    "            data_dic.append({'name': label, 'xmin': newPosition[0],\n",
    "                             'ymin': newPosition[1], 'xmax': newPosition[2],\n",
    "                             'ymax': newPosition[3]})\n",
    "        fileName = str(uuid.uuid4())\n",
    "        toPascalVocFormat(fileName, directory_name, data_dic)\n",
    "        cv.imwrite(os.path.join(directory_name, fileName+'.jpg'), img)\n",
    "        # plt.imshow(img)\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "864eb498-92f4-4694-b97e-0e21574b4597",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2000/2000 [01:30<00:00, 21.99it/s]\n",
      "100%|████████████████████████████████████████| 500/500 [00:03<00:00, 140.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset\n",
    "\n",
    "NUMBER_OF_TRAINING_IMAGES = 2000\n",
    "NUMBER_OF_TEST_IMAGES = 500\n",
    "image_generator(train, NUMBER_OF_TRAINING_IMAGES, paths['train_data'])\n",
    "image_generator(test, NUMBER_OF_TEST_IMAGES, paths['test_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429ae56-9a36-4776-9728-127fe69de903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c200b5c-395f-4691-93e5-3f908b23010f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNIST_OD",
   "language": "python",
   "name": "mnist_od"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
